#+TITLE: Building native WebRTC applicationsls against Pexip client API
#+LaTeX_HEADER: \input{title_page}

#+LaTeX_CLASS: article

#+LaTeX_CLASS_OPTIONS: [a4paper,11pt]
#+LaTeX_HEADER: \usepackage[margin=1in]{geometry}
#+LATEX_HEADER: \usepackage[hyperref,x11names]{xcolor}
#+LATEX_HEADER: \usepackage[colorlinks=true,urlcolor=SteelBlue4,linkcolor=Firebrick4]{hyperref}

#+LaTeX_HEADER: \usepackage[T1]{fontenc} 
#+LaTeX_HEADER: \usepackage[scaled]{beraserif}
#+LaTeX_HEADER: \usepackage[scaled]{berasans} 
#+LaTeX_HEADER: \usepackage[scaled]{beramono}

#+LaTeX_HEADER: \usepackage{microtype}
#+LaTeX_HEADER: \usepackage{amssymb,amsmath}
#+LaTeX_HEADER: \usepackage{fancyhdr} %For headers and footers
#+LaTeX_HEADER: \pagestyle{fancy} %For headers and footers
#+LaTeX_HEADER: \usepackage{lastpage} %For getting page x of y
#+LaTeX_HEADER: \usepackage{float} %Allows the figures to be positioned and formatted nicely
# #+LaTeX_HEADER: \floatstyle{boxed} %using this
#+LaTeX_HEADER: \restylefloat{figure} %and this command
#+LaTeX_HEADER: \usepackage{url} %Formatting of yrls
#+LaTeX_HEADER: \lhead{}
#+LaTeX_HEADER: \chead{}
#+LaTeX_HEADER: \rhead{Building Native WebRTC Apps}
#+LaTeX_HEADER: \lfoot{Pexip AS | Registered Company Number: BR015978}
#+LaTeX_HEADER: \cfoot{}
#+LaTeX_HEADER: \rfoot{Page \thepage}

#+LaTeX_HEADER: \usepackage{xcolor}
#+LaTeX_HEADER: \PassOptionsToPackage{hyperref,x11names}{xcolor}
#+LaTeX_HEADER: \definecolor{electricblue}{HTML}{0D2E63}
#+LaTeX_HEADER: \usepackage{tocloft}
#+LaTeX_HEADER: \usepackage{microtype}
#+LaTeX_HEADER: \renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
#+LaTeX_HEADER: \usepackage[breaklinks=true,linktocpage,xetex]{hyperref} 
#+LaTeX_HEADER: \hypersetup{colorlinks, citecolor=electricblue,filecolor=electricblue,linkcolor=electricblue,urlcolor=electricblue}

#+LATEX: \clearpage
#+OPTIONS: ^:nil

* Introduction

In the following article, we'll be covering the steps required to
build a complete working WebRTC based video and chat application using
the Pexip client REST API and native builds of WebRTC for both
Android and iOS platforms.

** Who this guide is for

This guide is intended for developers of iOS or Android applications
that want to create a custom work flow around the powerful video
interoperability and conferencing capabilities of the Pexip platform.
This guide assumes you have a good understanding of how to develop
applications for your chosen platform and are familiar with making
HTTP queries to REST API's from your platform of choice.  You should
also have basic familiarity with normal developer tools such as
building and compiling applications from a command line.

This guide will not cover general application design or user
experience but there are some recommendations in Sections
[[sec:iosDesignConsiderations]] and [[sec:androidDesignConsiderations]]

** Background reading

The examples here assume you are familiar with the basic operation of
the Pexip REST API for clients as documented here
https://docs.pexip.com/api_client/api_rest.htm You should also be
familiar the basic concepts of WebRTC as outlined here
https://webrtc.org/faq/ Along with this you should also be familiar
with the basic concepts of the Pexip platform here
https://docs.pexip.com/admin/admin_intro.htm and the services offered
by the platform here https://docs.pexip.com/admin/admin_services.htm

** A word on security

As there is potentially sensitive information traveling over the
client API, all client connections are performed over an HTTPS
connection.  Valid certificates should be installed for your platform
(see
https://docs.pexip.com/admin/certificate_management.htm?#overview) and
you should not use self signed certificates or make attempts to bypass
any OS level checks (e.g. Application Transport Security on the iOS
platform).  As you are in complete control of each HTTPS connection
you could even perform things like certificate pinning but this is
beyond the scope of this document.

You should also heed industry standard practices when parsing
information received either from user input or from any incoming
connection and also when storing / logging information e.g. passwords
or tokens to ensure your application does not compromise the users
security in any way.

* An introduction to the call flow

The following sequence diagrams outline the high level call flow
involved in setting up a connection to the Pexip service.  The
`Client` is your application making HTTP requests and the `MCU` is a
Pexip worker node in your deployment.  Worker nodes are normally
discovered using DNS SRV for a specific domain.

Full documentation of the client API can be found here
https://docs.pexip.com/api_client/api_rest.htm

** Getting access to the conference

This call flow shows just the basic API participant flow.  An API
participant has no media associated with it but is a fully fledged
participant that can control the conference, receive events, view the
roster list, send and receive chat messages and also send / receive
presentations.  When developing your application it is important to
get this call flow working reliably as it forms the basis for all
communications with the MCU.

The token you receive must be used for all subsequent transactions
with the MCU and it must be refreshed (the expiry time will be given
to you).  If you fail to provide a token or provide a token that is
invalid or expired that request will fail and once the original
request expires, your participant will be ejected from the conference.

If your conferencing worker nodes are behind some form of proxy
e.g. a reverse proxy for load balancing you may need to deal with HTTP
authentication challenges and or SSL certificate challenges.

Documentation for the client control requests can be found here
https://docs.pexip.com/api_client/api_rest.htm#client_summary

To discover the service via DNS SRV (see
https://docs.pexip.com/admin/dns_records.htm#connect for setup
details), you should take the conference URI from the user in the form
of ~conference@domain.org~ and extract the domain and conference
parts.  Perform a look up for ~_pexapp._tcp.domain.org~ to see if
there are any SRV records available for ~domain.org~.  If there are
none, you should just use the domains A record entry.  See Section
[[sec:dnssrv]] for details on sample DNS SRV implementations.

#+begin_src plantuml :file images/request_token_sequence.png
participant Client
participant MCU
Note left of Client: First, discover\nthe service using DNS SRV
Client -> Client: DNS SRV _pexapp._tcp
Client -> MCU: /request_token
Note right of MCU: Depending on the config\nyou may require PINs
MCU -> Client: PIN challenge
Client -> MCU: /request_token + PIN
MCU -> Client: OK + token info
Note left of Client: At this point you are an API\nparticipant that can\ncontrol the conference\nThere is no media yet
Client -> MCU: /events
Note over Client, MCU: Event stream for SSE
Note right of MCU: Once subscribed to\nthe event stream, \nyou will be sent\nevents about\nthe conference
Note left of Client: Tokens will expire\nYou will need to refresh
Client -> MCU: refresh_token + token
MCU -> Client: OK + new token
Note left of Client: When finished you can\nrelease the token
Client -> MCU: /release_token + token
MCU -> Client: OK
#+end_src

Once finished with your connection, you must perform the
~release_token~ request so the MCU can clear down any resources taken
by your client and potentially end the conference.  If you do not
release your token, the MCU will maintain the participant in the
roster list until the token expires.

*** Requesting a token

<<sec:requestToken>>

The token request is the very first contact you make with the client
API and determines all further actions.  See
https://docs.pexip.com/api_client/api_rest.htm#request_token for full
details.  You will need to make sure that any services (VMRs, Gateway rules)
configured on your deployment have aliases that match what you are
dialing or you will receive a not found response.  The
~request_token~ exchange is also where you will deal with any PINs
that may have been configured on the services or supply conference
extensions for Virtual Reception Rooms.  See the *PIN protected
conferences* and *Virtual Receptions* section of the above
~request_token~ documentation.

*** Understanding your token

The token provides a large amount of information about the service you
are connecting to.  The response to a successful ~request_token~
should be parsed out to provide the correct feedback to the user.  At
a minimum you should store the ~token~ string to use in headers for
all subsequent requests, the ~participant_uuid~ as this is needed in later
operations, your ~role~ as this will determine what you can and can't
do in a conference and your ~service_type~ as this determines what
type of conference you are in or if you are in a waiting room.

*** Subscribing to the event stream

Once you have a token you must subscribe to the event stream in order
to receive further updates about the conference.  See
https://docs.pexip.com/api_client/api_rest.htm#server_sent.  Once
subscribed, you will receive an initial burst of events detailed in
Section [[sec:initialsse]].  You can use your own implementation of the
W3C SSE spec (https://www.w3.org/TR/2011/WD-eventsource-20111020/) or
use a readily available off-the-shelf version - see Section
[[sec:examplecode]] for examples.

*** Refreshing a token

The ~expires~ field of the original ~request_token~ in Section
[[sec:requestToken]] will give you a time in seconds before the token
expires.  We recommend refreshing your token at an interval of
~expires/2~ seconds.  See
https://docs.pexip.com/api_client/api_rest.htm#refresh_token for full
information.

*** Releasing a token

This will disconnect you from the conference and clear any resources
used by your participant.  See
https://docs.pexip.com/api_client/api_rest.htm#release_token

** Initial SSE flow when first connecting

<<sec:initialsse>>

When you first connect the event source, the MCU will send you a set
of events so you can correctly display the initial list of
participants in the roster and prepare yourself.  The full list of events
can be seen here
https://docs.pexip.com/api_client/api_rest.htm#server_summary

The initial participant sync is useful for creating the roster list of
participants in your application and only happens on connection.
Stage updates show you who is currently "on the stage" i.e. visible in
the main window.  You can find out who is talking by looking at the
information in the participant update messages.

#+begin_src plantuml :file images/initial_sse_sequence.png
participant Client
participant MCU
Note over Client,MCU: API connection established
MCU->Client: SSE: hello
MCU->Client: SSE: conference_update
Note left of Client: status of conference\nlocks and mute
MCU->Client: SSE: participant_sync_begin
MCU->Client: SSE: participant_create
MCU->Client: SSE: participant_create
Note left of MCU: continues for all participants in conference
MCU->Client: SSE: participant_sync_end
MCU->Client: SSE: stage
Note left of Client: Who's on the stage
MCU->Client: SSE: ping
Note left of Client: keep-alive PING
#+end_src

** Dealing with subsequent SSEs

A full list of SSEs located here
https://docs.pexip.com/api_client/api_rest.htm#server_summary and
should be dealt with accordingly e.g. on a ~participant_create~
message, you should add a participant into the roster and potentially
display this information to the user.

** Sending and receiving presentations

There are two methods for sending / receiving presentations.  The
first is to respond to a ~presentation_started~ and
~presentation_frame~ event by requesting a ~presentation.jpg~ from the
MCU and displaying it to the user and every time you get a new
presentation frame event, requesting a new ~presentation.jpg~.  The
second is to establish a presentation call and the MCU will send you a
media stream (often referred to as an HD presentation) that you can
render.  For mobile clients, rendering two simultaneous video streams
is a lot of work and is not recommended so only the image based
presentation is shown here but there is documentation for the REST
calls required if you wish to do this.

*** Receiving a presentation

This example flow shows the reception of a presentation using images
from the MCU.  See
https://docs.pexip.com/api_client/api_rest.htm#presentation_start for
more information

#+begin_src plantuml :file images/presentation_jpeg_rx_sequence.png
participant Client
participant MCU
Note over Client,MCU: API connection established
MCU -> Client: SSE: presentation_start + name
Note left of Client: This event tells you\n<name> has started\na presentation
MCU -> Client: SSE: presentation_frame + ID
Note left of Client: There is a presentation\nframe with ID <ID>\navailable
Client -> MCU: /presentation.jpeg + token
Note right of MCU: Supply frame with ID\n or latest frame\nif not available
Note left of Client: Render JPG image
Note right of MCU: Presentation changed\ngenerate new frame
MCU -> Client: SSE: presentation_frame + ID
Client -> MCU: /presentation.jpeg + token
Note left of MCU: keep updating as required
MCU -> Client: SSE: presentation_stop
Note left of Client: Presentation has ended
#+end_src

*** Sending a presentation

This example flow shows the flow for presenting images from a client
device into the conference.

#+begin_src plantuml :file images/presentation_jpeg_tx_sequence.png
participant Client
participant MCU
Note over Client,MCU: API connection established
Note left of Client: Show an image picker\n to the user
Note left of Client: Get the raw JPEG data\n from the image
Note left of Client: Escalate the\npresentation call
Client -> MCU: /participants/<participant uuid>/calls + call_type = presentation
MCU -> Client: OK + JSON (presentation uuid)
Note left of Client: POST your presentation\ndata into the conference
Client -> MCU : /presentation + image data in multipart form
MCU -> Client: OK
Note right of MCU: MCU sends SSE event\nto users as in\nreceiving presentation\nflow above
Note left of Client: Stop presenting\nand deescalate
Client -> MCU: /participants/<participant uuid>/calls/<p uuid>/disconnect
MCU -> Client: OK
#+end_src

** Sending and receiving chat messages

Chat messages are broadcast to the entire conference.  There is no
one-to-one or private chat.

*** Sending chat messages

See https://docs.pexip.com/api_client/api_rest.htm#message

#+BEGIN_SRC plantuml :file images/chat_tx_sequence.png
participant Client
participant MCU
Note over Client,MCU: API connection established
Note left of Client: Capture message text\ncreate JSON payload
Client -> MCU: POST <conference>/message + payload
MCU -> Client: OK
MCU -> Client: SSE: message + payload
#+END_SRC

*** Receiving chat messages

See https://docs.pexip.com/api_client/api_rest.htm#message_event

 #+begin_src plantuml :file images/chat_rx_sequence.png
participant Client
participant MCU
Note over Client,MCU: API connection established
MCU -> Client: SSE: message + payload
Note left of Client: Examine content type\nand present message\nto user
#+end_src

** Establishing Media

Once connected to the conference as an API participant you can then
escalate media.  Media escalation can be audio only or a full
audio/video session.  This part of the call flow is more involved as
it requires you to setup media devices (cameras and microphones) and
also perform what is called the offer/answer dance whereby the two
participants in the conversation (your application and the MCU media
engine) decide what codecs to use and how best to route media to each
other using ICE negotiation.  It is here where you can set things like
bandwidth of the call and video resolution.

*** High level call flow

#+begin_src plantuml :file images/media_flow_sequence.png
participant Client
participant MCU
Note over Client,MCU: API connection established
Note left of Client: Build media stream\nAdd media tracks
Note left of Client: Gather ICE candidates
Note left of Client: Create SDP offer
Client -> MCU: <participant uuid>/calls + SDP offer 
Note right of MCU: Determine\nAnswer
MCU -> Client: OK + SDP answer + call UUID
Note left of Client: Hook up streams\nto tracks etc
Client -> MCU: /ack
Note right of MCU: Start sending\nmedia
Note over Client,MCU: Media is now established\nand media will flow\nClient API connection must\nbe maintained.
Note left of Client: You can alter media\n tracks e.g. to switch\ncamera
Client -> MCU: /disconnect
MCU -> Client: OK
#+end_src

The generation of SDP and ICE candidates is handled for you by the
WebRTC library and is explained below.

*** Initializing the RTCPeerConnection

The ~RTCPeerConnection~ object is the main interface to the WebRTC
library and is created using a factory.  First, we must first
initialize the SSL libraries underneath everything by running
~RTCInitializeSSL()~. Once we have that done, we can then create a
~RTCPeerConnectionFactory~ object and build the component
parts to create our ~RTCPeerConnection~ object.

First we need an ~RTCBundlePolicy~ set with ~maxCompat~ so as not to
bundle all media over a single port and we'll also need to fill in any
ICE server configuration at this point e.g. if your TURN/ICE servers
need any authentication setup (see
https://docs.pexip.com/admin/about_turn_server.htm for more
information)
We can then set our media constraints to show if we're offering video
or audio or both and also set the ~DtlsSrtpKeyAgreement~ to true.
Once we have those, we can pass them into the factory to produce our
RTCPeerConnection object.  For iOS, this could look like:

[[./images/peer_connection.png]]


*** Building media streams from tracks

<<sec:buildingMediaStreams>>

Once we have our ~RTCPeerConnectionFactory~, we can also use it to
create our media streams and assign our audio and video tracks to
them.  For iOS we'll be using ~AVFoundation~ sources and using the
~avFoundationVideoSource~, ~videoTrack~ and ~audioTrack~ methods of
the ~RTCPeerConnectionFactory~.  For iOS, this could look like:

[[./images/add_tracks.png]]

*** Creating the offer with ICE candidates

Creating the offer using the ~RTCPeerConnection~ object will trigger a
bunch of calls that must be handled by your delegate in particular:

 - RTCPeerConnection :: didChange newState RTCICEGatheringState

As this is what will return the final SDP back up to the application
so we can POST it to the MCU as our offer.  For iOS this could look like:

[[./images/peer_conn_offer.png]]

*** Mangling the SDP to set bandwidths and resolutions

Before we POST the SDP to the MCU we must manipulate our SDP to set
the supported bandwidth and resolutions for the call e.g. make this a
wCIF call at 384kbps.  You could make this decision on behalf of your
user by looking at the connectivity of the device e.g. WiFi or
Cellular or through selection from user input e.g. "High Quality"
might convert to a 2Mbps call @720p.  Bear in mind that this is only
what is offered to the MCU, it might not actually end up being
negotiated and honored.  For more information, the reader is pointed
to https://tools.ietf.org/html/rfc4566.  We can mangle the SDP once we
reach the ~RTCICEGatheringState.complete~ i.e. all the ICE candidates
have been discovered and added to the description and we only really
need to set the ~AS~ and ~TIAS~ setting for the total session
bandwidth and the RTC constraints for capture device to set the out bound
resolutions (~minWidth~).  For iOS, this could look like:

[[./images/sdp_mutation_functions.png]]

*** Sending the SDP offer

Once we have a complete offer with all candidates and we have
manipulated the SDP to what we want we can now POST this to the MCU.  
See https://docs.pexip.com/api_client/api_rest.htm#calls

*** Receiving the SDP answer

Once the MCU has calculated an answer for for our offer, it will send
back its response and we can then manipulate this further e.g. to
limit the out bound bandwidth from our device and then pass this into
our ~RTCPeerConnection~ objects ~remoteDescription~. For iOS, this
could look like:

[[./images/remote_sdp.png]]

*** Connecting streams

Once our ~RTCPeerConnection~ objects ~remoteDescription~ has been set
and accepted you can now connect up the incoming streams to your views
to display the video and play the sound when the delegate function fires:

 - RTCPeerConnection :: didAdd stream RTCMediaStream

In this event, you can pick out the audio and video streams and attach
them to your ~RTCEAGLView~ renderers i.e. the views you have setup to
show video in your app.  For iOS, this could look like:

[[./images/add_stream.png]]

*** Starting media flow

Once the offer/answer dance has completed and you have wired up your
streams, you can know trigger the MCU into sending media by sending an
~ack~ message: See https://docs.pexip.com/api_client/api_rest.htm#ack.
Once this completes, you should start to see and hear media in your
application.

*** Switching streams

You can switch tracks in the media stream to allow you to do things
like swapping between front and rear cameras.  You can do this using
~useBackCamera~ on the ~RTCAVFoundationVideoSource~ e.g.:

[[./images/toggle_camera.png]]

*** Crossing the streams

Never cross the streams, it would be bad.

*** Disconnecting media flow

Once you have finished you can disconnect the media and drop back down
to an API participant.  See
https://docs.pexip.com/api_client/api_rest.htm#call_disconnect

* Platform Specific Considerations
** iOS
*** WebRTC binaries

At the time of writing, there is no native support for WebRTC in the
safari view controller so the only way to work with WebRTC is via a
binary install of the WebRTC library and rendering the results
using RTCEAGLViews in your UI.  You will need to build the WebRTC
library yourself (see Section [[sec:buildingwebrtc]] ) and then include the
header files in your project.  If you are using Swift, make sure that
a bridging header is in place to expose the bindings.  All examples
for this document will use Swift but the concepts transfer directly
for Objective-C based applications.

The library can be compiled with the full instruction set for use on
all ARM platforms and also with 386 and X86_64 instructions for use in
the simulator.  You can control which platforms to target and hence
control the size of the included library.  When submitting to the App
Store, you *must* remove these non-ARM architectures from the
library or your app will be rejected.

*** Bitcode

At the time of writing, there is also no support for Bitcode in the
library so you will need to disable this for your project.

*** Hardware Acceleration

Hardware acceleration is enabled by default for the latest builds of
WebRTC and this should dramatically reduce the CPU load used when
decoding H264 streams but be aware that decoding video and audio is
still a very intensive workload and consideration should be taken when
deciding bandwidths and resolutions to negotiate with the MCU i.e. a
2Mbps stream at 720p HD resolution will require a modern ARM processor
and a lot of CPU power and older phones will struggle to decode this
in a timely manner.

On iOS devices with an A4 up to A6 processor, there is support for
H.264/AVC/MPEG-4 Part 10 (until profile 100 and up to level 5.1),
MPEG-4 Part 2, and H.263.  The A7 added support for H.264’s
profile 110.

** Android

For Android, there are actually two ways you can interact with WebRTC;
a web view with built in support for WebRTC that can be accessed via
JavaScript bindings; or using the same method as iOS with a WebRTC
library and a pure Java implementation.  See Sections
[[sec:buildingWebrtcAndroid]] and [[sec:androidDesignConsiderations]] for more
information.

* Building WebRTC

<<sec:buildingwebrtc>>

** Building WebRTC for iOS
*** Custom patches for Pexip

At the time of writing, there is a custom patch to workaround support
for rotation of video streams that must be applied in order for the
video stream to be rotated to the correct orientation.  See Section
[[sec:examplecode]] for links to the patches.

The reader is advised to use a "branch head" when building rather than
master as this is slightly more stable and reliable when building.  At
the time of writing, branch head 56 was used.

#+BEGIN_SRC sh
git checkout branch-heads/56
glclient sync
#+END_SRC

We recommend building the framework as this greatly simplifies
addition to your project although if you want more fine grained
control, you can build the static library and only include what you
need.

*** Building

Building WebRTC for iOS must be performed on a Mac - these examples
were performed on a Macbook Pro running macOS 10.12.1.  The canonical
build instructions are https://webrtc.org/native-code/ios/ but the
following process is a good summary.

**** Prerequisites
***** depot tools

Clone the depot tools

#+BEGIN_EXAMPLE
git clone https://chromium.googlesource.com/chromium/tools/depot_tools.git
#+END_EXAMPLE

Make sure they are in your path:

#+BEGIN_EXAMPLE
export PATH=`pwd`/depot_tools:$PATH
#+END_EXAMPLE

***** WebRTC code

Create a working directory, enter it and fetch the code:

#+BEGIN_EXAMPLE
mkdir ~/webrtc
cd ~/webrtc
fetch —nohooks webrtc_ios
#+END_EXAMPLE

Now sync and pull down the code.  This will take a long time and
should not be interrupted as multiple gigabytes of data will be
downloaded.

#+BEGIN_EXAMPLE
gclient sync
#+END_EXAMPLE

**** Building
<<sec:buildingWebRtc>> Once you have the source (and have applied any
necessary patches) you can either build a static binary or a
framework.  Building a framework is the simpler option but the static
binary gives you more control.


**** Building the framework

#+BEGIN_EXAMPLE
cd ~/webrtc/src
#+END_EXAMPLE

Build the framework:

#+BEGIN_EXAMPLE
./webrtc/build/ios/build_ios_libs.sh
#+END_EXAMPLE

The result will be a directory called ~out_ios_libs~ containing the
framework called ~WebRTC.framework~.  You can now embed this directly
into you project.

**** Building the static Binary

#+BEGIN_EXAMPLE
cd ~/webrtc/src
#+END_EXAMPLE

Build the static binary:

#+BEGIN_EXAMPLE
./webrtc/build/ios/build_ios_libs.sh -b static_only -o out
#+END_EXAMPLE

The result will be a library and a set of headers in the ~out~
directory.

The ~out~ directory will contain a single ~librtc_sdk_objc.a~ with all
architectures combined and sub directories containing the individual
architectures.  The header files will be located in
~./webrtc/sdk/objc/Framework/Headers/WebRTC/~

If the build script fails you can run the compilation manually:

#+BEGIN_EXAMPLE
gn gen out/arm64 --args='target_os="ios" target_cpu="arm64" \
is_component_build=false is_debug=false’
gn gen out/arm --args='target_os="ios" target_cpu="arm" \ 
is_component_build=false is_debug=false’

ninja -C out/arm64 rtc_sdk_framework_objc
ninja -C out/arm rtc_sdk_framework_objc
#+END_EXAMPLE


***** Adding WebRTC and headers to your Swift project

1. Create a new group in your project hierarchy called WebRTC and
   create a new header file called ~<bundle id>-Bridging-Header.h~
2. Copy in the binary lib and headers created in the build process above.
3. Add the import lines to the bridging header
   1. You can run the following command from the headers directory from Section [[sec:buildingWebRtc]] to
      get a listing ready to paste in:
      #+BEGIN_SRC awk
      ls *h | awk '{print "#import \"" $NF "\""}'
      #+END_SRC
      You won't need all of these headers and the macOS ones can be
      removed.
4. Make sure ~Build Settings -> Objective-C Bridging Header~ has a
   path set to the new bridging header you created
5. Include all the other frameworks and libraries required for proper
   operation including your freshly built ~librtc_sdk_objc~ library,
   in the following order:
   - libresolv.tbd
   - AVFoundation.framework
   - CoreMedia.framework
   - GLKit.framework
   - OpenGLES.framework
   - CoreVideo.framework
   - CoreAudio.framework
   - QuartzCore.framework
   - AudioToolbox.framework
   - libc++.tbd
   - libstdc++.tbd
   - VideoToolbox.framework
   - librtc_sdk_objc.a
*** Other settings

 - Make sure the ~Build Settings -> Other linker flags~ is set to
   ~-ObjC~ or you’ll get weird crashes about unknown signatures.
 - turn off bit-code support in ~Build Settings~
   
** Building WebRTC for Android

<<sec:buildingWebrtcAndroid>>

First, please take into account the design considerations mentioned in
Section [[sec:androidDesignConsiderations]] as this will determine if you
even need to compile WebRTC for Android.

The canonical build instructions are here
https://webrtc.org/native-code/android/ but at the time of writing are
still using the old ~gyp~ build system but the main repository has
moved over to the new ~gn~ build system.


* Example Code
<<sec:examplecode>>

The example code is intended as a rudimentary guide to show you the
basic concepts for working with the API and it *should not be used as
a basis for your application* as, for example, it does no validation
of user input, no error checking for responses from the API, no proper
layout of the video elements, no care for proper background operation
and no translation of any user interface elements into other
languages.  The examples also do not follow any of the HIGs laid out
by Apple
(https://developer.apple.com/ios/human-interface-guidelines/overview/design-principles/)
or Google (https://developer.android.com/design/index.html)

The example code can be found in https://github.com/pexip/pexkit-sdk.

** License

All examples and code are released under the MIT license:

#+BEGIN_EXAMPLE
The MIT License (MIT)

Copyright (c) 2016 Pexip

Permission is hereby granted, free of charge, to any person obtaining
a copy of this software and associated documentation files (the
"Software"), to deal in the Software without restriction, including
without limitation the rights to use, copy, modify, merge, publish,
distribute, sub license, and/or sell copies of the Software, and to
permit persons to whom the Software is furnished to do so, subject to
the following conditions:

The above copyright notice and this permission notice shall be
included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE
LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION
OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
#+END_EXAMPLE

** iOS
*** Design Considerations
<<sec:iosDesignConsiderations>>
It's a good idea to encapsulate the Conference functionality
(e.g. token handling, event handling, chat, presentation and call
handling) into a single class and the Call functionality (dealing with
WebRTC) in another class.  You can also setup structures for important
pieces of information e.g. resolutions, service errors etc

*** DNS SRV
<<sec:dnssrv>>
We have provided an example DNS SRV code snippet that you may include
in your projects if you prefer not to implement your own.

*** SSE
A good example of an SSE implementation is
https://github.com/inaka/EventSource.  We have successfully used this
to connect to the Pexip SSE stream.

*** Audio Routing
By default, audio will be routed to the earpiece on the phone.  You
can override this using the ~AVAudioSession~ as below (~.Speaker~ is
just an Enum for clarity)

[[./images/audio_routing_swift.png]]

You should modify this once the audio track has been established.

*** Selfview
If you wish to display a self view (i.e. the local video track), you
can hook up another ~RTCEAGLVideoView~ to the video track as follows:

#+BEGIN_SRC swift
self.videoTrack?.add(self.videoSelfView!)
#+END_SRC

This should be added in the initialisation of the call where you
create media streams.

** Android

*** Design Considerations

<<sec:androidDesignConsiderations>>

As WebRTC is implemented in the Chrome web view for the Android
platform, there are a couple of options open to you when working with
WebRTC.  Firstly, you can work with the native web view and call the
REST API as the iOS client or you can use a wrapper around our PexRTC
JavaScript bindings to alleviate some of the work required.

The following examples assume you are using Android Studio and an API
Level of 21 or above.

**** To bundle PexRTC.js or not

In order to use PexRTC.js you can either bundle the JavaScript with the wrapper project or fetch the JavaScript from your running deployment.

The wrapper includes a function called ~fetchPexRTCSource~ that will
pull in the running version of PexRTC on the targeted deployment.
You should make sure that any functions you are calling are still
supported in the current version.

The supplied wrapper already includes a bundled version of PexRTC, you
may need to update this every time you publish your app.

**** Building the wrapper

Simply open the supplied project and build it.  This will produce an
AAR file (in ~pexrtc-android-wrapper/app/build/outputs/aar~)

*** PexRTC wrapper

Import the wrapper library into your project using "File --> New -->
New Module" and select "import JAR/AAR package" from the selection.

Then navigate to the AAR wrapper file and import it.  Once complete,
you will now have this available in your resources side bar.

Open you project structure ("File --> Project Structure") then select
your existing "app" module and then select the dependencies tab and
add (+) a module dependency and select the AAR submodule you just
imported.

From your app, you should now be able to import
~com.pexip.android.wrapper.PexView~ 

You can now add in your PexView (either or programmatically or via
adding it to your layout.xml file).

**** fragments vs normal view destruction

For configuration changes e.g. rotation, there are two methods of
dealing with the view destruction: use fragments or disable view
destruction (non-fragment way).

The following example uses the non-fragment method so you will need to
add the following line to your android manifest inside the activity:

#+BEGIN_SRC xml
android:configChanges="orientation|screenSize"
#+END_SRC

e.g.

#+BEGIN_SRC java
  <activity android:name=".MainActivity"
       android:configChanges="orientation|screenSize" >
       <intent-filter>
       <action android:name="android.intent.action.MAIN" />
     
       <category android:name="android.intent.category.LAUNCHER" />
       </intent-filter>
   </activity>
#+END_SRC

**** pro grammatic addition of PexView

In your ~onCreate~ method of your main activity:

#+BEGIN_SRC java
final PexView pexView = new PexView(this);
#+END_SRC

Once you've have this, you can then grab the ID of your layout
(e.g. ~myLayoutId~) from your layout XML file and then add the PexView
to it.

#+BEGIN_SRC java
RelativeLayout layout = (RelativeLayout) findViewById(R.id.myLayoutId);
layout.addView(pexView);
#+END_SRC

If you wish to show a self view:

#+BEGIN_SRC java
WebView selfView = new WebView(this);
layout.addView(selfView);
pexView.setSelfView(selfView);
#+END_SRC

**** addition via layout.xml

Using the design view, add a custom view (search for PexView) and add
it where you see fit and then link them to your main activity e.g.

#+BEGIN_SRC java
PexView pexView = (PexView) findViewById(R.id.pexViewId);
WebView selfView = (WebView) findViewById(R.id.selfViewID);
pexView.setSelfView(selfView);
#+END_SRC

**** setting up callbacks for events

Once you have your views setup, you can now register the callbacks for
the events from PexRTC e.g.

#+BEGIN_SRC java
  pexView.setEvent("onSetup", pexView.new PexEvent() {
          @Override
          public void onEvent(String[] strings) {
              pexView.setSelfViewVideo(strings[0]);
              pexView.evaluateFunction("connect");
          }
      });

  pexView.setEvent("onConnect", pexView.new PexEvent() {
          @Override
          public void onEvent(String[] strings) {
              if (strings.length > 0 && strings[0] != null)
                  pexView.setVideo(strings[0]);
          }
      });

  pexView.addPageLoadedCallback(pexView.new PexCallback() {
          @Override
          public void callback(String args) {
              // make a call
              pexView.evaluateFunction("makeCall", "pexipdemo.com", "meet.vmr", "My Display Name", "576");
          }
      });

  // Load the page which will then trigger the callbacks
  pexView.load();



#+END_SRC

**** adding permissions to the android manifest

You'll need the following permissions in your manifest file:

#+BEGIN_SRC xml
<uses-permission android:name="android.permission.INTERNET"/>
<uses-permission android:name="android.permission.CAMERA"/>
<uses-permission android:name="android.permission.MODIFY_AUDIO_SETTINGS"/>
<uses-permission android:name="android.permission.RECORD_AUDIO"/>
#+END_SRC

*** Native

Follow iOS instructions if you wish to go the native route.

** Cordova

We have created a fork of the official Cordova plugin to work with the
latest WebRTC.  Access to these plugins will be made available at a
later date.
